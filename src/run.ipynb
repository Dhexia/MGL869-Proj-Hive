{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa166c8f436bbb8",
   "metadata": {},
   "source": [
    "# MGL869 - Projet personnel\n",
    "\n",
    "*MGL869 ETS Montreal - Production engineering*\n",
    "\n",
    "## Abstract\n",
    "\n",
    "## Authors\n",
    "- **William PHAN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc574ebf57602201",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1 : Collecte des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5caf94fc63fdaf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T23:44:33.397217Z",
     "start_time": "2024-11-20T23:44:31.076236Z"
    }
   },
   "outputs": [],
   "source": [
    "from Jira import jira_download\n",
    "from pandas import Index\n",
    "from numpy import ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4622a84f52ca68",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 - Téléchargement des données Jira\n",
    "\n",
    "Nous téléchargeons les données si elles ne sont pas déjà présentes dans le dossier de données.\n",
    "\n",
    "Renvoie le dataframe des données.\n",
    "\n",
    "Le filtre de requête peut être défini dans le fichier config.ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4971d821b405286",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T23:47:00.218802Z",
     "start_time": "2024-11-20T23:46:59.751178Z"
    }
   },
   "outputs": [],
   "source": [
    "jira_dataframe = jira_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f051f67cbe342b",
   "metadata": {},
   "source": [
    "### 1.2 - Nettoyer les données Jira en utilisant pandas\n",
    "\n",
    "Auparavant, nous avons téléchargé toutes les données de Jira. Maintenant, nous allons nettoyer les données en utilisant pandas. Nous allons conserver seulement certaines colonnes et combiner certaines colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c04fde21e36891",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep: [str] = ['Issue key', 'Status', 'Resolution', 'Created', 'Fix Versions Combined', 'Affects Versions Combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d14c6e651890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "affects_version_columns: [str] = [col for col in jira_dataframe.columns if col.startswith('Affects Version/s')]\n",
    "jira_dataframe['Affects Versions Combined'] = jira_dataframe[affects_version_columns].apply(\n",
    "    lambda x: ', '.join(x.dropna().astype(str)), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1571fc3d63fa3d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the versions into a single column\n",
    "fix_version_columns: [str] = [col for col in jira_dataframe.columns if col.startswith('Fix Version/s')]\n",
    "\n",
    "jira_dataframe['Fix Versions Combined'] = jira_dataframe[fix_version_columns].apply(\n",
    "    lambda x: ', '.join(x.dropna().astype(str)), axis=1\n",
    ")\n",
    "jira_dataframe = jira_dataframe.loc[:, keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7229ab85b247aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns whose names contain the string 'Issue key'\n",
    "issue_key_columns: Index = jira_dataframe.columns[jira_dataframe.columns.str.contains('Issue key')]\n",
    "# Extract the values from these columns as a NumPy array\n",
    "issue_key_values: ndarray = jira_dataframe[issue_key_columns].values\n",
    "# Flatten the array to create a one-dimensional list of all 'Issue key' values\n",
    "flattened_issue_keys: ndarray = issue_key_values.flatten()\n",
    "# Convert the list into a set to remove duplicates\n",
    "ids: set = set(flattened_issue_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56c59729f4f2bd8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Part 2 : Analyse du répo git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5c65ce22975fa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T23:48:05.000004Z",
     "start_time": "2024-11-20T23:48:04.804273Z"
    }
   },
   "outputs": [],
   "source": [
    "from Hive import git_download, commit_analysis, update_commit_dataframe, filter_versions_by_min\n",
    "from git import Repo, Tag\n",
    "from pandas import DataFrame\n",
    "from configparser import ConfigParser\n",
    "from re import compile\n",
    "from packaging import version  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7e1094fe45f12b",
   "metadata": {},
   "source": [
    "### 2.1 - Clonage du répo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da70cec527312bb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T23:48:07.689653Z",
     "start_time": "2024-11-20T23:48:06.629293Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repo: Repo = git_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440e0445aebd0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_couples = commit_analysis(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc716ced26d7531a",
   "metadata": {},
   "source": [
    "### 2.2 - Filtrage des données et couples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bac11954b2066d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T04:16:26.388221Z",
     "start_time": "2024-11-20T04:16:26.378513Z"
    }
   },
   "outputs": [],
   "source": [
    "commit_dataframe: DataFrame = DataFrame(all_couples, columns=[\"Issue key\", \"File\", \"Commit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c98946d2120458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T04:16:26.415350Z",
     "start_time": "2024-11-20T04:16:26.403683Z"
    }
   },
   "outputs": [],
   "source": [
    "# Languages without whitespaces\n",
    "config: ConfigParser = ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "languages: [str] = config[\"GENERAL\"][\"Languages\"].split(\",\")\n",
    "languages: [str] = [lang.strip() for lang in languages]\n",
    "commit_dataframe: DataFrame = commit_dataframe[commit_dataframe['File'].str.endswith(tuple(languages))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9ce9d7-7636-45b4-826a-f55535ef28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "couples = update_commit_dataframe(commit_dataframe, jira_dataframe)\n",
    "couples\n",
    "filtered_couples = couples[couples['Version Affected'].str.contains('2.3.9', na=False)]\n",
    "filtered_couples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f496352e0c7a43f5",
   "metadata": {},
   "source": [
    "### 2.3 - Collecte des versions filtrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6fbf64ca7a8f6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T04:16:26.555772Z",
     "start_time": "2024-11-20T04:16:26.432450Z"
    }
   },
   "outputs": [],
   "source": [
    "releases_regex: [str] = config[\"GIT\"][\"ReleasesRegex\"].split(\",\")\n",
    "tags: Tag = repo.tags\n",
    "versions: dict = {tag.name: tag.commit for tag in tags}\n",
    "releases_regex: [str] = [regex.strip() for regex in releases_regex]\n",
    "releases_regex = [compile(regex) for regex in releases_regex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418d3b719f004c46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T04:16:26.585618Z",
     "start_time": "2024-11-20T04:16:26.571752Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_versions = filter_versions_by_min(versions, releases_regex, \"2.0.0\")\n",
    "filtered_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3efa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging.version import Version\n",
    "\n",
    "sorted_versions = dict(\n",
    "    sorted(filtered_versions.items(), key=lambda item: Version(item[0]), reverse=True)\n",
    ")\n",
    "\n",
    "sorted_versions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bda8a7e729d746e",
   "metadata": {},
   "source": [
    "## Part 3. - Analyse des métriques statiques via Understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341333382b3f4712",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T04:16:26.628016Z",
     "start_time": "2024-11-20T04:16:26.602950Z"
    }
   },
   "outputs": [],
   "source": [
    "from Understand.commands import und_create_command, und_purge_command\n",
    "from Understand.metrics import metrics\n",
    "from Understand.label import label_all_metrics\n",
    "from os import path\n",
    "from Understand import merge_static_metrics\n",
    "from Understand.enrich import enrich_metrics\n",
    "from Understand.update import merge_all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8504cac8b12909",
   "metadata": {},
   "source": [
    "### 3.1 - Création du projet Understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897f593172bee81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T04:16:26.651135Z",
     "start_time": "2024-11-20T04:16:26.645112Z"
    }
   },
   "outputs": [],
   "source": [
    "hive_git_directory: str = config[\"GIT\"][\"HiveGitDirectory\"]\n",
    "data_directory: str = config[\"GENERAL\"][\"DataDirectory\"]\n",
    "understand_project_name : str = config[\"UNDERSTAND\"][\"UnderstandProjectName\"]\n",
    "\n",
    "understand_project_path : str = path.join(data_directory, hive_git_directory, understand_project_name)\n",
    "\n",
    "if not path.exists(understand_project_path):\n",
    "    und_create_command()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fadd76a26bddbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T04:16:27.831068Z",
     "start_time": "2024-11-20T04:16:26.670397Z"
    }
   },
   "outputs": [],
   "source": [
    "und_purge_command()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e1f947-5bde-4984-8adc-86b859a1ad59",
   "metadata": {},
   "source": [
    "### 3.2 - Extraction des métriques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dab79156306ac6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-20T04:16:27.848863Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "metrics(filtered_versions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aa23e7-801e-469e-a10d-9bea94b91aff",
   "metadata": {},
   "source": [
    "### 3.3 - Labélisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78f4b34-6a24-4a64-b04a-e20bb44a1473",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all_metrics(couples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95599321",
   "metadata": {},
   "outputs": [],
   "source": [
    "enrich_metrics(couples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352890b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [\n",
    "    \"2.0.0\", \"2.0.1\", \"2.1.0\", \"2.1.1\", \"2.2.0\", \"2.3.0\", \"2.3.1\", \"2.3.2\",\n",
    "    \"2.3.3\", \"2.3.4\", \"2.3.5\", \"2.3.6\", \"2.3.7\", \"2.3.8\", \"2.3.9\", \"2.3.10\",\n",
    "    \"3.0.0\", \"3.1.0\", \"3.1.1\", \"3.1.2\", \"3.1.3\", \"4.0.0\", \"4.0.1\"\n",
    "]\n",
    "merge_all_metrics(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af76593-116f-4987-8a28-e04608c16334",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_static_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3594ec81",
   "metadata": {},
   "source": [
    "# Part 4. - Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87e311-3c64-47dc-b398-e44bfc25733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from configparser import ConfigParser\n",
    "from AI import plot_feature_importance_rf, plot_shap_summary,plot_shap_with_others, evaluate_model, train_model, load_and_prepare_data, load_config\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd950f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "config: ConfigParser = ConfigParser()\n",
    "config.read(\"config.ini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0aaa4f",
   "metadata": {},
   "source": [
    "### 4.1 - Evaluation of RF and LR models for all versions\n",
    "\n",
    "Dans cette partie, il est important de souligner que le modèle construit se base sur les données du csv augmentée contenant le résultat de TOUTES les versions taguées depuis la 2.0.0. Le fichier se trouve dans le dossier src/Output/temp_static_metrics_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec0dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = config[\"GENERAL\"][\"DataDirectory\"]\n",
    "output_dir = config[\"UNDERSTAND\"][\"FullStaticMetricsOutputDirectory\"]\n",
    "file_name = config[\"UNDERSTAND\"][\"MergedStaticMetricsFileName\"]\n",
    "file_path = os.path.join(data_directory, output_dir, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b723c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve configuration settings\n",
    "config_section = \"VERSION_ALL_LAB\"\n",
    "param = load_config(config_section)\n",
    "\n",
    "model_instance_lr = LogisticRegression(max_iter=5000, class_weight='balanced')\n",
    "print(\"Running pipeline with the model: Logistic Regression\")\n",
    "X_train_lr, X_test_lr, y_train_lr, y_test_lr = load_and_prepare_data(file_path,param)\n",
    "trained_model_lr = train_model(model_instance_lr, X_train_lr, y_train_lr)\n",
    "metrics_lr = evaluate_model(trained_model_lr, X_test_lr, y_test_lr) \n",
    "\n",
    "# Random Forest\n",
    "model_instance_rf = RandomForestClassifier(class_weight='balanced')\n",
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = load_and_prepare_data(file_path,param)\n",
    "print(\"Running pipeline with the model: Random Forest\")\n",
    "trained_model_rf = train_model(model_instance_rf, X_train_rf, y_train_rf)\n",
    "metrics_rf = evaluate_model(trained_model_rf, X_test_rf, y_test_rf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a4818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f483857",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679715a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(metrics_lr[\"FPR\"], metrics_lr[\"TPR\"],\n",
    "         label=f\"Logistic Regression (AUC = {metrics_lr['AUC']:.2f})\")\n",
    "plt.plot(metrics_rf[\"FPR\"], metrics_rf[\"TPR\"],\n",
    "         label=f\"Random Forest (AUC = {metrics_rf['AUC']:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Classifier\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for All Versions')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19c8db4",
   "metadata": {},
   "source": [
    "#### Analyse des métriques :\n",
    "AUC (aire sous la courbe ROC):\n",
    "L’AUC de Random Forest (0.96) est largement supérieure à celle de Logistic Regression (0.64). Cela montre que Random Forest est bien meilleur pour séparer les classes (positifs vs négatifs).\n",
    "\n",
    "Précision :\n",
    "Random Forest a une précision de 96 % contre 63 % pour Logistic Regression. Cela signifie que Random Forest fait beaucoup moins d’erreurs quand il prédit une classe positive.\n",
    "\n",
    "Rappel (Recall) :\n",
    "Avec un rappel de 91 %, Random Forest détecte presque tous les vrais positifs, alors que Logistic Regression n’en détecte que 46 %.\n",
    "\n",
    "#### Conclusion :\n",
    "Le modèle Random Forest est clairement le plus performant. Voici pourquoi :\n",
    "\n",
    "Il a un AUC proche de 1, ce qui montre qu'il distingue très bien les classes positives et négatives.\n",
    "Il est très précis (96 %) dans ses prédictions.\n",
    "Il détecte la grande majorité des positifs réels grâce à son rappel élevé (91 %)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762c63d7",
   "metadata": {},
   "source": [
    "### 4.2 Étude de l'importance des métriques appliqué au modèle de régression linéaire (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71217b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shap_summary(trained_model=trained_model_lr, X_train=X_train_lr, X_test=X_test_lr, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4b12c6",
   "metadata": {},
   "source": [
    "#### Analyse : CountSemicolon \n",
    "\n",
    "Rouge à droite (valeurs élevées) : Les valeurs élevées de CountSemicolon (points rouges) tendent à être à droite (SHAP positif). Cela indique qu'un grand nombre de points-virgules dans un fichier augmente la probabilité qu'il contienne un bogue.\n",
    "Bleu (valeurs faibles) : Les faibles valeurs de CountSemicolon (points bleus) sont centrées autour de zéro. Cela signifie que lorsque CountSemicolon est faible, cette variable a peu d'influence sur la prédiction.\n",
    "\n",
    "#### Analyse : CountStmtExe\n",
    "Rouge à gauche (SHAP négatif) :\n",
    "\n",
    "Les points rouges indiquent des valeurs élevées de CountStmtExe.\n",
    "Ces points rouges sont majoritairement situés à gauche (valeurs SHAP négatives). Cela signifie que plus la valeur de CountStmtExe est élevée, plus elle diminue la probabilité qu'un fichier contienne un bug.\n",
    "Impact sur les prédictions :\n",
    "\n",
    "Grand nombre de points rouges à gauche :\n",
    "Cela montre que beaucoup de fichiers avec des valeurs élevées de CountStmtExe (nombre d'instructions exécutables) réduisent la probabilité prédite d’un bug.\n",
    "Cela peut indiquer que des fichiers contenant un grand nombre d’instructions exécutables (potentiellement bien organisées ou bien testées) sont moins susceptibles de contenir des bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b88cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_shap_with_others(trained_model=trained_model_lr, X_train=X_train_lr, X_test=X_test_lr, top_n=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2310edd7",
   "metadata": {},
   "source": [
    "Cette vue résume uniquement l’importance globale (moyenne) absolue, sans afficher les relations locales ni les distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29e33c3",
   "metadata": {},
   "source": [
    "### 4.3 Étude de l'importance des métriques appliqué au modèle de forêt aléatoire (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3b5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance_rf(trained_model_rf=trained_model_rf, feature_columns=X_train_rf.columns, top_n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3808bf5c",
   "metadata": {},
   "source": [
    "### Analyse des résultats et suggestions d'actions pour éviter les bogues\n",
    "\n",
    "À partir des graphiques montrant les **importances des variables** et les **valeurs SHAP** dans Random Forest uniquement (le meilldeur modèle), nous pouvons identifier les métriques ayant le plus d'impact sur la probabilité de présence d'un bogue. Ces analyses permettent de proposer des actions concrètes pour améliorer la qualité du code et éviter des bogues.\n",
    "\n",
    "---\n",
    "\n",
    "#### Actions proposées :\n",
    "\n",
    "1. **Réduire le nombre de déclarations de variables dans les classes (`CountDeclClassVariable`)**\n",
    "   - **Observation :** `CountDeclClassVariable` est la métrique la plus influente. Un grand nombre de variables déclarées dans une classe peut rendre le code complexe, difficile à maintenir, et sujet à des erreurs.\n",
    "   - **Action :**\n",
    "     - Encourager la modularisation des classes en utilisant des sous-classes ou des objets pour encapsuler les variables liées.\n",
    "     - Limiter le nombre de variables par classe avec des revues de code automatiques.\n",
    "   - **Justification :**\n",
    "     - Une classe plus concise facilite la lisibilité et diminue les risques d’introduction de bogues liés à des dépendances complexes.\n",
    "\n",
    "\n",
    "\n",
    "2. **Optimiser la gestion des classes de base (`CountClassBase`)**\n",
    "   - **Observation :** Le nombre de classes de base est fortement corrélé à la probabilité de bogues. Cela peut indiquer des hiérarchies de classes complexes ou mal conçues.\n",
    "   - **Action :**\n",
    "     - Simplifier les hiérarchies de classes en limitant la profondeur d’héritage.\n",
    "     - Appliquer des principes de conception comme **Composition over Inheritance** pour réduire la dépendance à de multiples classes de base.\n",
    "   - **Justification :**\n",
    "     - Des hiérarchies simplifiées favorisent une meilleure lisibilité et limitent les erreurs dues à des relations mal comprises entre classes.\n",
    "\n",
    "\n",
    "\n",
    "3. **Réduire la complexité des entrées (`CountInput`)**\n",
    "   - **Observation :** Un nombre élevé d’entrées peut indiquer une complexité dans la gestion des données ou une forte dépendance à des sources externes.\n",
    "   - **Action :**\n",
    "     - Standardiser les formats d’entrée et limiter les dépendances aux données externes non fiables.\n",
    "     - Ajouter des validations robustes pour éviter les erreurs dues à des données inattendues.\n",
    "   - **Justification :**\n",
    "     - Une gestion claire et standardisée des entrées diminue les risques d’erreurs dues à des données mal formées ou non prévues.\n",
    "\n",
    "\n",
    "\n",
    "4. **Contrôler le nombre total de méthodes déclarées (`CountDeclMethodAll`)**\n",
    "   - **Observation :** Un grand nombre de méthodes déclarées est corrélé à une complexité accrue, ce qui augmente les risques de bogues.\n",
    "   - **Action :**\n",
    "     - Refactoriser les classes pour réduire le nombre de méthodes, par exemple en regroupant des fonctionnalités similaires.\n",
    "     - Limiter le nombre de méthodes publiques pour réduire l’exposition à des erreurs externes.\n",
    "   - **Justification :**\n",
    "     - Réduire le nombre de méthodes facilite la compréhension et diminue les risques d’introduire des erreurs dans des classes complexes. **Attention**, cependant une subdivision trop pauvre du code aura un effet inverse !\n",
    "\n",
    "\n",
    "\n",
    "5. **Limiter les modifications de couplage des classes (`CountClassCoupledModified`)**\n",
    "   - **Observation :** Les modifications fréquentes des relations entre classes couplées sont associées à une probabilité accrue de bogues.\n",
    "   - **Action :**\n",
    "     - Minimiser les modifications fréquentes des classes couplées en favorisant la stabilité des interfaces.\n",
    "     - Utiliser des tests automatisés pour valider les modifications dans les dépendances.\n",
    "   - **Justification :**\n",
    "     - Réduire les modifications dans des dépendances critiques diminue le risque d’introduire des bogues dans les interactions entre classes.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ... Vers une analyse plus fine\n",
    "Bien que ces analyses offrent des perspectives globales basées sur toutes les versions combinées, elles ne tiennent pas compte de l'évolution des métriques au fil des versions. Il serait pertinent d'explorer comment ces métriques varient entre les versions pour mieux comprendre l'impact des changements dans le temps. Cela permettra d'identifier des tendances ou des patterns susceptibles de causer des bogues dans les futures versions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb17ad9",
   "metadata": {},
   "source": [
    "## Part 5. - Limitations du modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff29ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AI import plot_feature_importance_rf, plot_shap_summary,plot_shap_with_others, evaluate_model, train_model, load_and_prepare_data, load_config, train_and_save_models, plot_metrics_evolution\n",
    "import os, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635fbf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3659fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = config[\"GENERAL\"][\"DataDirectory\"]\n",
    "output_dir = config[\"UNDERSTAND\"][\"StaticModelsDirectory\"]\n",
    "file_name = config[\"MODEL\"][\"StaticPerformanceMetricsFile\"]\n",
    "file_path = os.path.join(data_directory, output_dir, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43007dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"r\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "filtered_results = {version: metrics for version, metrics in results.items()}\n",
    "\n",
    "plot_metrics_evolution(filtered_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9aa789-37de-43e9-9e5f-7744ca9fd466",
   "metadata": {},
   "source": [
    "## Part 6. - Dynamic Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f6b052-94da-4262-a7e1-b68137787f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dynamic import convert_json_to_csv, merge_static_and_dynamic_csv, build_dependencies, display_hierarchy, collect_dynamic_metrics_v2\n",
    "from Hive import filter_versions_by_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61014ea2-93c8-4e80-ae0a-773903d6ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_versions = filter_versions_by_min(versions, releases_regex,'1.0')\n",
    "version_json = build_dependencies(all_versions)\n",
    "#display_hierarchy(version_json)\n",
    "#version_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef68223c-f8cd-422a-a157-e2fe7671fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_metrics = collect_dynamic_metrics_v2(version_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba249385-6dbc-4b9c-8e02-ac4010b5daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_json_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4861e-4f61-49fc-a018-911a58a29d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_static_and_dynamic_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
